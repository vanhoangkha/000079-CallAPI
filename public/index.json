[
{
	"uri": "/3-deploy-lambda-function/3-1-create-dynamodb-table/",
	"title": "Create DynamoDB table",
	"tags": [],
	"description": "",
	"content": " Open DynamoDB console Click Create table  Enter table name: Books   Enter parition key: id Enter sort key: rv_id (review id), type is Number  Scroll down to Table settings pattern, select Customize settings   Then, select On-demand Click Create local Index  Enter sort key: name   Click Create index  Scroll down to the bottom, click Create table  So we have created the Books table with the Local secondary index of name-index\nTo add data to the table, you can download the file below:  \r\rData\r\r\rdynamoDB.json\r\r(4 ko)\r\r\r\r Open this file, replace all \u0026lt;AWS-REGION\u0026gt; with the region where you created the S3 book-image-resize-store bucket, for example: ap-southeast-2\n  Run the following command in the directory where you save the dynamoDB.json\n  aws dynamodb batch-write-item --request-items file://dynamoDB.json "
},
{
	"uri": "/4-config-api-gw/4-1-create-methods/",
	"title": "Create methods",
	"tags": [],
	"description": "",
	"content": "Create list API  Click Actions, then select Create method  Select GET method  Click to \u0026ldquo;check\u0026rdquo; icon  Select Lambda Function for Integration type   Check to Use Lambda Proxy integration Enter Lambda function name to be integrated: books_list Click Save  Click OK  Create write API  Click Actions, then select Create method  Select POST method   Click to \u0026ldquo;check\u0026rdquo; icon  Select Lambda Function for Integration type   Check to Use Lambda Proxy integration Enter Lambda function name to be integrated: book_create Click Save  Click OK  Create delete API  Click Actions, then select Create Resource  Enter id for Resource name pattern   Enter {id} for Resource path pattern Click Create Resource  Click Actions, then select Create method  Select method DELETE   Click to \u0026ldquo;check\u0026rdquo; icon  Select Lambda Function for Integration type   Check to Use Lambda Proxy integration Enter Lambda function name to be integrated: book_delete Click Save  Click OK  So, we have created the APIs that interact with Lambda functions.\n"
},
{
	"uri": "/1-introduction/",
	"title": "Introduction API Gateway / DynamoDB",
	"tags": [],
	"description": "",
	"content": "Overview Introducing API Gateway Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the \u0026ldquo;front door\u0026rdquo; for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.\nAPI Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management. API Gateway has no minimum fees or startup costs. You pay for the API calls you receive and the amount of data transferred out and, with the API Gateway tiered pricing model, you can reduce your cost as your API usage scales.\nAPI Types RESTful APIs Build RESTful APIs optimized for serverless workloads and HTTP backends using HTTP APIs. HTTP APIs are the best choice for building APIs that only require API proxy functionality. If your APIs require API proxy functionality and API management features in a single solution, API Gateway also offers REST APIs.\nWEBSOCKET APIs Build real-time two-way communication applications, such as chat apps and streaming dashboards, with WebSocket APIs. API Gateway maintains a persistent connection to handle message transfer between your backend service and your clients.\nHow API Gateway Works Introducing DynamoDB You can refer to the DynamoDB workshop for more information\n DynamoDB Basic Advanced DynamoDB  "
},
{
	"uri": "/",
	"title": "Serverless - Build Frontend to call API Gateway",
	"tags": [],
	"description": "",
	"content": "Serverless - Build Frontend to call API Gateway Overview In the last post, we know how to create and use Lambda functions that interact with S3 and DynamoDB. Next in this series, we build a web application (front-end) to interact with the database through Lambda and API Gateway.\nThe architecture of the application we will build:\nContent  Introduction Front-end deployment Deploy Lambda function Config API Gateway Test API by Postman Test API with front-end Cleanup  "
},
{
	"uri": "/3-deploy-lambda-function/3-2-deploy-lambda-function/3-2-1-write-data-function/",
	"title": "Writing Lambda function",
	"tags": [],
	"description": "",
	"content": "In this step, we will update the code for the book_create created function in post 1:\n Open AWS Lambda console  Click book_create function  Copy the below code block into lambda_function.py  import boto3\rimport json\rimport base64\rimport io\rimport cgi\rimport os\rs3 = boto3.client(\u0026#39;s3\u0026#39;)\rclient = boto3.resource(\u0026#39;dynamodb\u0026#39;)\rruntime_region = os.environ[\u0026#39;AWS_REGION\u0026#39;]\rdef get_data_from_request_body(content_type, body):\rfp = io.BytesIO(base64.b64decode(body)) # decode\renviron = {\u0026#34;REQUEST_METHOD\u0026#34;: \u0026#34;POST\u0026#34;}\rheaders = {\r\u0026#34;content-type\u0026#34;: content_type,\r\u0026#34;content-length\u0026#34;: len(body),\r}\rfs = cgi.FieldStorage(fp=fp, environ=environ, headers=headers) return [fs, None]\rdef lambda_handler(event, context):\rcontent_type = event[\u0026#39;headers\u0026#39;].get(\u0026#39;Content-Type\u0026#39;, \u0026#39;\u0026#39;) or event[\u0026#39;headers\u0026#39;].get(\u0026#39;content-type\u0026#39;, \u0026#39;\u0026#39;)\rif content_type == \u0026#39;application/json\u0026#39;:\rbook_item = json.loads(event[\u0026#34;body\u0026#34;])\relse:\rbook_data, book_data_error = get_data_from_request_body(\rcontent_type=content_type, body=event[\u0026#34;body\u0026#34;]\r)\rname = book_data[\u0026#39;image\u0026#39;].filename\rimage = book_data[\u0026#39;image\u0026#39;].value\rs3.put_object(Bucket=\u0026#39;book-image-store\u0026#39;, Key=name, Body=image)\rimage_path = \u0026#34;https://{}.s3.{}.amazonaws.com/{}\u0026#34;.format(\u0026#34;book-image-resize-store\u0026#34;, runtime_region, name)\rbook_item = {\r\u0026#34;id\u0026#34;: book_data[\u0026#39;id\u0026#39;].value,\r\u0026#34;rv_id\u0026#34;: 0,\r\u0026#34;name\u0026#34;: book_data[\u0026#39;name\u0026#39;].value,\r\u0026#34;author\u0026#34;: book_data[\u0026#39;author\u0026#39;].value,\r\u0026#34;price\u0026#34; : book_data[\u0026#39;price\u0026#39;].value,\r\u0026#34;category\u0026#34;: book_data[\u0026#39;category\u0026#39;].value,\r\u0026#34;description\u0026#34;: book_data[\u0026#39;description\u0026#39;].value,\r\u0026#34;image\u0026#34;: image_path\r}\rtable = client.Table(\u0026#39;Books\u0026#39;)\rtable.put_item(Item = book_item)\rresponse = {\r\u0026#39;statusCode\u0026#39;: 200,\r\u0026#39;body\u0026#39;: \u0026#39;successfully created item!\u0026#39;,\r\u0026#39;headers\u0026#39;: {\r\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;,\r\u0026#34;Access-Control-Allow-Headers\u0026#34;: \u0026#34;Access-Control-Allow-Headers, Origin, Accept, X-Requested-With, Content-Type, Access-Control-Request-Method,X-Access-Token, XKey, Authorization\u0026#34;,\r\u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET,PUT,POST,DELETE,OPTIONS\u0026#34;\r},\r}\rreturn response  Then, click Deploy  The new code handles the images that the user wants to upload and is saved in the S3 bucket\n\rIf you create S3 buckets with names different from the lab, replace them in lines 35 and 36 of code\n\rGive the Lambda function permission to write a file to the S3 bucket.   Click Configuration tab Select Permissions pattern on the left menu Click on the role the function is executing   Click on the existing policy that starts with AWSLambdaExecutionRole-   Click Edit policy   Click JSON tab and add the blow json block:  ,\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::book-image-store/*\u0026#34;\r}  Click Review policy   Review the settings and click Save changes  "
},
{
	"uri": "/3-deploy-lambda-function/3-2-deploy-lambda-function/",
	"title": "Deploy Lambda function",
	"tags": [],
	"description": "",
	"content": "In this step, we will create Lambda functions to read, write, and delete data in DynamoDB. Then grant the necessary permissions to those functions.\nNội dung  Update writing Lambda function Create listing Lambda function Create deleting Lambda function  "
},
{
	"uri": "/2-front-end-deployment/",
	"title": "Front-end deployment",
	"tags": [],
	"description": "",
	"content": "In the first step in this workshop, we will host the web application (front-end) with S3 Static website hosting:\n Open Amazon S3 console  Click Create bucket  Enter bucket name, such as: fcj-book-store   Select the region closest to you  Uncheck block from allowing public access   Check to I acknowledge that the current settings might result in this bucket and the objects within becoming public  Click Create bucket button  Click on created bucket  Click Properties tab  Scroll down to the bottom, click Edit in Static web hosting pattern  Select Enable to enable host web static on S3   Select Host a static website for Hosting type Enter index.html for Index document pattern  Click Save changes   After successfully enabling, please write down the path of the web  Select Permissions tab   Click Edit of Bucket policy pattern  Copy the below code block to Policy  {\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::fcj-book-store/*\u0026#34;\r}\r]\r}  Click Save changes  Download fcj-serverless-frontend code to device   Open command-line/terminal in the folder where you want to save the source code Copy the below commands  git clone https://github.com/AWS-First-Cloud-Journey/FCJ-Serverless-Workshop.git\rcd fcj-serverless-frontend\rnpm install\ryarn build We have finished building the front-end. Next execute the following command to upload the build folder to S3  aws s3 cp build s3://fcj-book-store --recursive \rIf your upload fails, configure the access key ID, secret access key, aws region and output format with aws configure command\n\rResult after uploading:\nPaste the web link you take notes into your web browser  Your application currently has no data returned. To get data from DynamoDB, go to the next section.\n"
},
{
	"uri": "/3-deploy-lambda-function/3-2-deploy-lambda-function/3-2-2-list-data-function/",
	"title": "Listing Lambda function",
	"tags": [],
	"description": "",
	"content": "We will create a Lambda function that reads all the data in the DynamoDB table:\n Click Create function  Enter function name, such as: books_list   Select Python 3.9 for Runtime pattern Click Create function  Copy the below code block and paste to lambda_function.py.  import json\rimport boto3\rfrom decimal import *\rfrom boto3.dynamodb.types import TypeDeserializer\rclient = boto3.client(\u0026#39;dynamodb\u0026#39;) serializer = TypeDeserializer()\rclass DecimalEncoder(json.JSONEncoder):\rdef default(self, obj):\rif isinstance(obj, Decimal):\rreturn str(obj)\rreturn json.JSONEncoder.default(self, obj)\rdef deserialize(data):\rif isinstance(data, list):\rreturn [deserialize(v) for v in data]\rif isinstance(data, dict):\rtry:\rreturn serializer.deserialize(data)\rexcept TypeError:\rreturn {k: deserialize(v) for k, v in data.items()}\relse:\rreturn data\rdef lambda_handler(event, context):\rdata_books = client.scan(\rTableName=\u0026#39;Books\u0026#39;,\rIndexName=\u0026#39;name-index\u0026#39;\r)\rformat_data_books = deserialize(data_books[\u0026#34;Items\u0026#34;])\rfor book in format_data_books:\rdata_comment = client.query(\rTableName=\u0026#34;Books\u0026#34;, KeyConditionExpression=\u0026#34;id = :id AND rv_id \u0026gt; :rv_id\u0026#34;, ExpressionAttributeValues={\r\u0026#34;:id\u0026#34;: {\u0026#34;S\u0026#34;: book[\u0026#39;id\u0026#39;]}, \u0026#34;:rv_id\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;0\u0026#34;}\r}\r)\rformat_data_comment = deserialize(data_comment[\u0026#39;Items\u0026#39;])\rprint(data_comment[\u0026#39;Items\u0026#39;])\rbook[\u0026#34;comments\u0026#34;] = format_data_comment\rprint (format_data_books)\rreturn {\r\u0026#34;statusCode\u0026#34;: 200,\r\u0026#34;headers\u0026#34;: {\r\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;,\r\u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET,PUT,POST,DELETE, OPTIONS\u0026#34;,\r\u0026#34;Access-Control-Allow-Headers\u0026#34;: \u0026#34;Access-Control-Allow-Headers, Origin,Accept, X-Requested-With, Content-Type, Access-Control-Request-Method,X-Access-Token,XKey,Authorization\u0026#34;\r},\r\u0026#34;body\u0026#34;: json.dumps(format_data_books, cls=DecimalEncoder)\r}  Click Deploy  Next, give the function permission to read data from DynamoDB   Click Configuration tab Select Permissions pattern on the left menu Click on the role the function is executing   Click on the existing policy that starts with AWSLambdaExecutionRole-   Click Edit policy   Click JSON tab and add the below json block:  ,\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;dynamodb:Scan\u0026#34;,\r\u0026#34;dynamodb:Query\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:AWS_REGION:ACCOUNT_ID:table/Books\u0026#34;\r}  Replace AWS_REGION with the region where you create the table in DynamoDB, such as: ap-southeast-2 Replace ACCOUNT_ID with your account id Click Review policy   Review the settings and click Save changes  "
},
{
	"uri": "/4-config-api-gw/4-2-setting-and-cors/",
	"title": "Setting and enable CORS",
	"tags": [],
	"description": "",
	"content": "In this section, we will add binary file support settings and enable CORS for the APIs\n Select Settings on the left menu.   Click Add Binary Media Type  Enter multipart/form-data   Click Save Changes  After the setting is done, back to Resource on the left menu.   Select /books resource Click Actions Select Enable CORS  Click Enable CORS and replace existing CORS headers  Click Yes, replace existing values   Enable CORS for successful GET and POST methods  Select books/{id} resource   Click Actions Select Enable CORS  Click Enable CORS and replace existing CORS headers  Click Yes, replace existing values   Enable CORS for successful DELETE method  To front-end can use APIs, we need deploy APIs.   Select / resource Click Actions Select Deploy API  Select New stage  Enter stage name, such as: staging  Take note URL to call API   URL of list and write API:   URL of delete API:  "
},
{
	"uri": "/3-deploy-lambda-function/3-2-deploy-lambda-function/3-2-3-delete-data-function/",
	"title": "Deleting Lambda function",
	"tags": [],
	"description": "",
	"content": "We will create a Lambda function that deletes all items with the specified partition key and sort key in the DynamoDB table. And delete the image file in the S3 bucket:\n Click Create function  Enter function name, ví dụ: book_delete   Select Python 3.9 for Runtime pattern Click Create function  Copy the below code block into lambda_function.py  import boto3\rimport json\rs3 = boto3.client(\u0026#39;s3\u0026#39;)\rclient = boto3.resource(\u0026#39;dynamodb\u0026#39;)\rdef get_image_name(image_path):\rstr_image = image_path.split(\u0026#34;/\u0026#34;)\rfor image_path_item in str_image:\rimage_name = image_path_item\rreturn image_name;\rdef lambda_handler(event, context):\rerror = None\rstatus = 200\rdelete_id = event[\u0026#39;pathParameters\u0026#39;]\rdelete_id[\u0026#39;rv_id\u0026#39;] = 0\rtable = client.Table(\u0026#34;Books\u0026#34;)\rimage_path = \u0026#34;\u0026#34;\rtry:\rdata = table.get_item(Key = delete_id)\rimage_path = data[\u0026#39;Item\u0026#39;][\u0026#39;image\u0026#39;]\rimage_name = get_image_name(image_path)\rexcept Exception as e:\rerror = e\rtry:\rresponse = table.query(\rProjectionExpression=\u0026#34;rv_id\u0026#34;, KeyConditionExpression=\u0026#34;id = :id\u0026#34;, ExpressionAttributeValues={\u0026#34;:id\u0026#34;: delete_id[\u0026#39;id\u0026#39;]})\rfor item in response[\u0026#39;Items\u0026#39;]:\rdelete_id[\u0026#39;rv_id\u0026#39;] = item[\u0026#39;rv_id\u0026#39;]\rprint(delete_id)\rtable.delete_item(Key = delete_id)\rprint(image_name)\rs3.delete_object(Bucket=\u0026#39;book-image-resize-store\u0026#39;, Key=image_name)\rexcept Exception as e:\rerror = e\rif error is None:\rmessage = \u0026#39;successfully deleted item!\u0026#39;\relse:\rmessage = \u0026#39;delete item fail\u0026#39;\rstatus = 400\rreturn {\r\u0026#39;statusCode\u0026#39;: status,\r\u0026#39;body\u0026#39;: message,\r\u0026#39;headers\u0026#39;: {\r\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;,\r\u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39;\r},\r}  Click Deploy  If you create S3 bucket with name different from the lab, replace it in line 42 of code\n\rNext, give the Lambda function permission to delete object from the S3 bucket and access to DynamoDB table.   Click Configuration tab Select Permissions pattern on the left menu Click on the role the function is executing   Click on the existing policy that starts with AWSLambdaExecutionRole-   Click Edit policy   Click JSON tab and add the blow json block:  ,\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;dynamodb:DeleteItem\u0026#34;,\r\u0026#34;dynamodb:GetItem\u0026#34;,\r\u0026#34;dynamodb:Query\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:dynamodb:AWS_REGION:ACCOUNT_ID:table/Books\u0026#34;,\r\u0026#34;arn:aws:s3:::book-image-resize-store/*\u0026#34;\r]\r}  Replace AWS_REGION with the region where you create the table in DynamoDB, such as: ap-southeast-2 Replace ACCOUNT_ID with your account id Click Review policy   Review the settings and click Save changes  "
},
{
	"uri": "/3-deploy-lambda-function/",
	"title": "Deploy Lambda function",
	"tags": [],
	"description": "",
	"content": "In this section, we will create three Lambda functions to write, read and erase data in DynamoDB with Python. If you did the cleanup in workshop 1 of the series, recreate the Lambda function and S3 bucket according to workshop 1\nNội dung  Create DynamoDB table Deploy Lambda function  "
},
{
	"uri": "/4-config-api-gw/",
	"title": "Config API Gateway",
	"tags": [],
	"description": "",
	"content": "Next, we\u0026rsquo;ll set up the API Gateway to interact with the Lambda functions created in the previous section:\n Open API Gateway console  Scroll down and click Build of REST API pattern  Click OK  Select REST for Protocol   Select New API to create a new API Enter REST API name, such as: fcj-serverless-api Click Create API  Click on the API just created  Click Actions, then select Create resource  Enter resource name, such as: books   Then click Create Resource  So we have created a new REST API and resource for it. Next, we will create methods to interact with Lambda functions and set them:\n Create methods Setting and enable CORS  "
},
{
	"uri": "/5-test-api-by-postman/",
	"title": "Test APIs by Postman",
	"tags": [],
	"description": "",
	"content": "In this step, we will test operation of the APIs using Postman tool.\nTest the listing API  Click + to add a new tab   Select GET method Enter URL of the listing API that recorded from the previous step Click Send  The returned result is the entire data of the Books table that has been processed  Test the writing API  Similarly create a new tab   Select POST method Enter URL of the writing API that recorded from the previous step In Body pattern, select raw Copy the below text block:  {\r\u0026#34;id\u0026#34;: \u0026#34;5\u0026#34;,\r\u0026#34;rv_id\u0026#34;: 0,\r\u0026#34;name\u0026#34;: \u0026#34;Amazon Web Services in Action 2nd Edition\u0026#34;,\r\u0026#34;author\u0026#34;: \u0026#34;Andreas Wittig\u0026#34;,\r\u0026#34;price\u0026#34;: \u0026#34;59.99\u0026#34;,\r\u0026#34;category\u0026#34;: \u0026#34;IT\u0026#34;,\r\u0026#34;description\u0026#34;: \u0026#34;Amazon Web Services in Action, Second Edition is a comprehensive introduction to computing, storing, and networking in the AWS cloud. You\u0026#39;ll find clear, relevant coverage of all the essential AWS services you to know, emphasizing best practices for security, high availability and scalability.\u0026#34;,\r\u0026#34;image\u0026#34;: \u0026#34;https://book-image-resize-store.s3.ap-southeast-2.amazonaws.com/aws.jpg\u0026#34;\r} Switch to Headers   Add KEY is Content-Type, VALUE is application/json Click Send  Wait a moment, see the results returned  Open Books table in DynamoDB console to check data   Before call the write API   After call the write API  Test the deleting API Since the delete Lambda function on execution deletes images uploaded by the user, we manually upload the images to the S3 bucket so the API can run properly.\n  Open Amazon S3 console\n  Click book-image-store bucket\n  Click Upload  Click Add files  Tải ảnh sau về máy của bạn và chọn nó để tải lên bucket  \r\r\rImage\r\r\raws.jpg\r\r(24 ko)\r\r\r\r6. Click Upload After the upload is done, switch to book-image-resize-store bucket to check. This is execution result of reszie_image Lambda funtion  Back to Postman, add a new tab to call the delete API   Select DELETE method Enter URL of the deleting API that recorded from the previous step, replace /{id} with /5 Click Send  Check the returned result:  Open Books table in DynamoDB console to check data  Open book-image-resize-store bucket to check object. The aws.jpg is deleted  "
},
{
	"uri": "/6-test-front-end/",
	"title": "Test APIs with front-end",
	"tags": [],
	"description": "",
	"content": "After testing that the APIs work properly with Postman, we will test the APIs that are called with the front-end built from part 2.\n Open config.js in fcj-serverless-frontend folder that downloaded from part 2   Change value of APP_API_URL with your URL:  Open App.js in fcj-serverless-frontend/src/, change value of isAdmin with true Run the command lines under here:  yarn build\raws s3 cp build s3://fcj-book-store --recursive Paste the endpoint of S3 static web into your browser. The app already shows the book information, but still no pictures because we haven\u0026rsquo;t uploaded the pictures yet.  So the listing API is working properly\nTest writing API   Click Management tab Click Update   Edit whatever you want except id Click Choose image Upload the below image to the bucket: \r\rImage\r\r\rDockerInAction.jpeg\r\r(33 ko)\r\r\r\r Click Update   Click OK   Image and information updated   Click on the Create new book tab to write new data to the database Enter id with 5 Enter name: Amazon Web Services in Action Enter the author: Andreas Wittig Enter category: IT Enter price: 59.99 Enter a description: Amazon Web Services in Action, Second Edition is a comprehensive introduction to computing, storing, and networking in the AWS cloud. You\u0026rsquo;ll find clear, relevant coverage of all the essential AWS services you to know, emphasizing best practices for security, high availability, and scalability.  \r\rImage\r\r\raws.jpg\r\r(24 ko)\r\r\r\r Press the Choose File button to upload the image Press the Create button   Click OK   Display newly created information   Test the deleting API   Click Management tab Click Update   Click Delete   Click OK to confirm delete   Click OK   View results after deleting: no appearing book information  We have finished building a simple SAM-based web application following the serverless model.\n"
},
{
	"uri": "/7-cleanup/",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Delete DynamoDB table   Open DynamoDB console Select Tables on the left menu Select Books table Click Delete Enter delete and click Delete table  Delete S3 bucket   Open S3 console Select book-image-resize-store bucket Click Empty Enter permanently delete and click Empty Select fcj-book-store bucket Click Empty Enter permanently delete and click Empty Select book-image-resize-store bucket Click Delete Enter book-image-resize-store and click Delete Select book-image-store bucket Click Delete Enter book-image-store and click Delete Select fcj-book-store bucket Click Delete Enter fcj-book-store and click Delete  Delete REST API   Open API Gateway console Select fcj-serverless-api Click Actions and select Delete Click Delete  Delete Lambda functions   Open AWS Lambda console Select book_create function Click Actions Select Delete Enter delete and click Delete Similar to resize_image, books_list, book_create, book_delete function  "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]